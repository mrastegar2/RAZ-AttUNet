{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib .pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.util import img_as_float\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "\n",
    "# you can select dataset_no from 1 to 5 to train each fold\n",
    "dataset_no=1\n",
    "i=str(dataset_no)\n",
    "\n",
    "main_path = r\"/path/to/dataset/\"\n",
    "\n",
    "data_path =main_path+'\\Fold'+ i +'\\Train'\n",
    "\n",
    "patch_size=128\n",
    "rows = patch_size\n",
    "cols = patch_size\n",
    "\n",
    "img_rows = patch_size\n",
    "img_cols = patch_size\n",
    "\n",
    "SEED = 42\n",
    "#Setting the seed ensures that, if you run the data augmentation process multiple times, you'll get the same augmented images in each run, which can be important for reproducibility.\n",
    "\n",
    "smooth =5.\n",
    "#############################################################################\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -K.log(dice_coef(y_true, y_pred))\n",
    "\n",
    "def load_train_data():\n",
    "    train_images_path = os.path.join(data_path, 'Images')\n",
    "    train_masks_path = os.path.join(data_path, 'Masks')\n",
    "    images = os.listdir(train_images_path)\n",
    "    masks = os.listdir(train_masks_path)\n",
    "    total = len(images)\n",
    "\n",
    "    rimgs = np.empty((total, rows, cols), dtype=np.float32)\n",
    "    rmsks = np.empty((total, rows, cols), dtype=np.float32)\n",
    "\n",
    "    i = 0\n",
    "    print('Convert training images to arrays')\n",
    "    print('------------------------------------------')\n",
    "    for image_name in images:\n",
    "        img = imread(os.path.join(train_images_path, image_name))\n",
    "        img = img_as_float(img)\n",
    "        rimg = resize(img, (rows, cols), preserve_range=True)\n",
    "\n",
    "        rimgs[i] = rimg\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Done: {0}/{1} images'.format(i, total))\n",
    "        i += 1\n",
    "    print('Done.')\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    i = 0\n",
    "    print('Convert training masks to arrays')\n",
    "    print('------------------------------------------')\n",
    "    for mask_name in masks:\n",
    "        msk = imread(os.path.join(train_masks_path, mask_name))\n",
    "        img = img_as_float(img)\n",
    "        rmsk = resize(msk, (rows, cols), preserve_range=True)\n",
    "\n",
    "        rmsks[i] = rmsk\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Done: {0}/{1} masks'.format(i, total))\n",
    "        i += 1\n",
    "    print('Done.')\n",
    "    print('------------------------------------------')\n",
    "\n",
    "    return rimgs, rmsks\n",
    "\n",
    "def my_generator(x_train, y_train, batch_size):\n",
    "    data_generator = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            rotation_range=10,\n",
    "            zoom_range=0.1,\n",
    "            fill_mode='nearest').flow(x_train, x_train, batch_size, seed=SEED)\n",
    "\n",
    "    mask_generator = ImageDataGenerator(\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=True,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            rotation_range=10,\n",
    "            zoom_range=0.1,\n",
    "            fill_mode='nearest').flow(y_train, y_train, batch_size, seed=SEED)\n",
    "    while True:\n",
    "        x_batch, _ = data_generator.next()\n",
    "        y_batch, _ = mask_generator.next()\n",
    "        yield x_batch, y_batch\n",
    "\n",
    "def conv_block(x, num_filters):\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    x = L.Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = L.BatchNormalization()(x)\n",
    "    x = L.Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(x, num_filters):\n",
    "    x = conv_block(x, num_filters)\n",
    "    p = L.MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def attention_gate(g, s, num_filters):\n",
    "    Wg = L.Conv2D(num_filters, 1, padding=\"same\")(g)\n",
    "    Wg = L.BatchNormalization()(Wg)\n",
    "\n",
    "    Ws = L.Conv2D(num_filters, 1, padding=\"same\")(s)\n",
    "    Ws = L.BatchNormalization()(Ws)\n",
    "\n",
    "    out = L.Activation(\"relu\")(Wg + Ws)\n",
    "    out = L.Conv2D(num_filters, 1, padding=\"same\")(out)\n",
    "    out = L.Activation(\"sigmoid\")(out)\n",
    "\n",
    "    return out * s\n",
    "\n",
    "def decoder_block(x, s, num_filters):\n",
    "    x = L.UpSampling2D(interpolation=\"bilinear\")(x)\n",
    "    s = attention_gate(x, s, num_filters)\n",
    "    x = L.Concatenate()([x, s])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def attention_unet():\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = L.Input((img_rows, img_cols, 1), name=\"input_first\")\n",
    "\n",
    "    \"\"\" Encoder \"\"\"\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "\n",
    "    b1 = conv_block(p3, 512)\n",
    "\n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s3, 256)\n",
    "    d2 = decoder_block(d1, s2, 128)\n",
    "    d3 = decoder_block(d2, s1, 64)\n",
    "\n",
    "    \"\"\" Outputs \"\"\"\n",
    "    outputs = L.Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d3)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = Model(inputs, outputs, name=\"Attention-UNET\")\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-4), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "    \n",
    "    return model\n",
    "\n",
    "class StopOnDiceChange(Callback):\n",
    "    def __init__(self, min_delta=0.001, patience=5):\n",
    "        \"\"\"\n",
    "        Stops training if the change in val_dice_coef is below min_delta for 'patience' epochs.\n",
    "        \n",
    "        :param min_delta: Minimum change in val_dice_coef to consider as an improvement.\n",
    "        :param patience: Number of consecutive epochs with small change before stopping.\n",
    "        \"\"\"\n",
    "        super(StopOnDiceChange, self).__init__()\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.wait = 0\n",
    "        self.prev_val_dice = None\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_dice = logs.get('val_dice_coef')\n",
    "\n",
    "        if val_dice is not None:\n",
    "            if self.prev_val_dice is not None:\n",
    "                dice_change = abs(val_dice - self.prev_val_dice)\n",
    "\n",
    "                if dice_change < self.min_delta:\n",
    "                    self.wait += 1\n",
    "                    print(f\"Epoch {epoch+1}: val_dice_coef change {dice_change:.6f} < min_delta {self.min_delta} ({self.wait}/{self.patience})\")\n",
    "                    \n",
    "                    if self.wait >= self.patience:\n",
    "                        print(f\"\\nStopping training: val_dice_coef change below {self.min_delta} for {self.patience} consecutive epochs.\")\n",
    "                        self.model.stop_training = True\n",
    "                else:\n",
    "                    self.wait = 0  # Reset counter if there is improvement\n",
    "\n",
    "            self.prev_val_dice = val_dice  # Store previous val_dice_coef\n",
    "#############################################################################\n",
    "\n",
    "print('Load and process train data')\n",
    "print('------------------------------')\n",
    "imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "imgs_train = imgs_train.astype('float32')\n",
    "mean = np.mean(imgs_train)  # mean for data centering\n",
    "std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "imgs_train -= mean\n",
    "imgs_train /= std\n",
    "\n",
    "imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "imgs_train = imgs_train.reshape(imgs_train.shape[0], rows, cols, 1)\n",
    "imgs_mask_train = imgs_mask_train.reshape(imgs_mask_train.shape[0], rows, cols, 1)\n",
    "\n",
    "fix, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(imgs_train[0, :, :, 0], cmap='gray')\n",
    "ax[1].imshow(imgs_mask_train[0, :, :, 0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(imgs_train, imgs_mask_train, test_size=0.2)\n",
    "\n",
    "print('Create and compile model')\n",
    "print('------------------------')\n",
    "model = attention_unet()\n",
    "\n",
    "model_no=dataset_no\n",
    "model_name='RAZ'+str(model_no)+'-2025-JMI'+str(patch_size)+'.h5'\n",
    "model_checkpoint = ModelCheckpoint(model_name, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "print('------------------------')\n",
    "#calculate steps_per_epoch\n",
    "s_p_e=round(len(os.listdir(os.path.join(data_path, 'Images')))/10)\n",
    "history = model.fit(my_generator(x_train, y_train, 10), steps_per_epoch=s_p_e,  validation_data=(x_val, y_val), epochs=999999, verbose=2, callbacks=[StopOnDiceChange(min_delta=0.001, patience=5)])\n",
    "\n",
    "model.save(model_name)\n",
    "\n",
    "##########################################################\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "toc = time.time()\n",
    "\n",
    "print ((toc-tic)/60, 'Processing Time in Minutes: ' )\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['dice_coef'])\n",
    "plt.plot(history.history['val_dice_coef'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
