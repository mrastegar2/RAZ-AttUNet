{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the biggest connected component and specify non-detected images (with no connected component detected)\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "prediction_folder= '/path/to/dataset/predictions'\n",
    "\n",
    "def keep_biggest_connected_component(image_path, output_path):\n",
    "    # Get a list of all image files in the predictions path\n",
    "    image_files = [f for f in os.listdir(image_path) if f.endswith(('.bmp'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"No image files found in the specified path.\")\n",
    "        return\n",
    "    \n",
    "    filenames_no_component = []\n",
    "    no_filenames_no_component=0\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        # Read the image\n",
    "        image = cv2.imread(os.path.join(image_path, image_file), cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Threshold the image to get a binary representation\n",
    "        _, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Find connected components\n",
    "        _, labels, stats, _ = cv2.connectedComponentsWithStats(binary_image)\n",
    "\n",
    "        # Check if any connected components were found\n",
    "        if len(stats) <= 1:\n",
    "            #print(f\"No connected components found in {image_file}. keep the original file.\")\n",
    "            output_file = os.path.join(output_path,f\"{image_file}\")\n",
    "            cv2.imwrite(output_file, image)\n",
    "            filenames_no_component.append(image_file)\n",
    "            no_filenames_no_component+=1\n",
    "            continue\n",
    "\n",
    "        # Find the index of the largest connected component\n",
    "        largest_component_index = np.argmax(stats[1:, cv2.CC_STAT_AREA]) + 1\n",
    "\n",
    "        # Create a mask to keep only the largest connected component\n",
    "        mask = np.zeros_like(binary_image)\n",
    "        mask[labels == largest_component_index] = 255\n",
    "\n",
    "        # Save or process the result as needed\n",
    "        output_file = os.path.join(output_path, f\"{image_file}\")\n",
    "        cv2.imwrite(output_file, mask)\n",
    "    \n",
    "    if filenames_no_component:\n",
    "        print(f\"The filenames with no connected components are: {filenames_no_component}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"No such files found.\")\n",
    "\n",
    "    return filenames_no_component, no_filenames_no_component\n",
    "\n",
    "\n",
    "Predictions_bcc_path =  '/path/to/dataset/Result_att/Predictions_bcc'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(Predictions_bcc_path, exist_ok=True)\n",
    "\n",
    "[f_n_c,no_filenames_no_cc]=keep_biggest_connected_component(prediction_folder, Predictions_bcc_path)\n",
    "print(no_filenames_no_cc,' non-detected images (with no connected component detected) files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##keep the second biggest connected component for patients with a cyst larger than the RAZ\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.measure import label\n",
    "from skimage.io import imsave\n",
    "\n",
    "# Set folder path\n",
    "prediction_folder= '/path/to/dataset/predictions'\n",
    "output_folder = '/path/to/dataset/predictions_2bcc'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to process image, i.e. keep the second biggest connected component\n",
    "def process_image(image_path, output_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Threshold to binary (you can adjust threshold value)\n",
    "    _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Convert to boolean\n",
    "    binary = binary > 0\n",
    "\n",
    "    # Label connected components\n",
    "    labeled = label(binary)\n",
    "\n",
    "    # Get sizes of components\n",
    "    component_sizes = np.bincount(labeled.ravel())\n",
    "    component_sizes[0] = 0  # background is label 0\n",
    "\n",
    "    if len(component_sizes) < 2:\n",
    "        print(f\"No second largest component found in {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Get label of second largest component\n",
    "    second_largest_label = component_sizes.argsort()[-2]\n",
    "\n",
    "    # Keep only second largest component\n",
    "    second_largest = (labeled == second_largest_label).astype(np.uint8) * 255\n",
    "\n",
    "    imsave(output_path, second_largest)\n",
    "\n",
    "# Loop through all predictions\n",
    "for filename in os.listdir(prediction_folder):\n",
    "    if filename.lower().endswith(\".bmp\"):\n",
    "        full_path = os.path.join(prediction_folder, filename)\n",
    "        out_path = os.path.join(output_folder, filename)\n",
    "        process_image(full_path, out_path)\n",
    "        print(f\"Processed: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill any holes inside a binary object\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def fill_holes_inside_object(binary_object):\n",
    "    # Create a kernel for morphological operations\n",
    "    kernel = np.ones((15, 15), np.uint8)\n",
    "\n",
    "    # Perform closing operation to fill holes inside the binary object\n",
    "    closed_object = cv2.morphologyEx(binary_object, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return closed_object\n",
    "\n",
    "def process_images(path1, path2):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(path2, exist_ok=True)\n",
    "\n",
    "    No_post_pro=0\n",
    "    # List all files in the input directory\n",
    "    files = [f for f in os.listdir(path1) if os.path.isfile(os.path.join(path1, f))]\n",
    "\n",
    "    for file in files:\n",
    "        # Read the binary image\n",
    "        image_path = os.path.join(path1, file)\n",
    "        binary_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # Ensure the image is binary (convert to grayscale and threshold if necessary)\n",
    "        _, binary_image = cv2.threshold(binary_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Assume you have a binary object and you want to fill holes inside it\n",
    "        # Extract the region of interest (ROI) containing the object\n",
    "        # You may need to perform segmentation or contour detection to isolate the object\n",
    "        \n",
    "        binary_object = binary_image.copy()\n",
    "\n",
    "        # Find the largest connected component\n",
    "        filled_object = fill_holes_inside_object(binary_object)\n",
    "        output_path = os.path.join(path2, file)\n",
    "        cv2.imwrite(output_path, filled_object)\n",
    "        No_post_pro+=1\n",
    "        \n",
    "    print(\"No_post_pro\",No_post_pro)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path1 = '/path/to/dataset/Result_att/Predictions_bcc'\n",
    "    path2 = path1 + '_Fill_holles'\n",
    "    process_images(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average of some images needed to be replaced (with no connected component detected)\n",
    "from skimage import io\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "#import os\n",
    "\n",
    "def read_binary_images(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".bmp\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            # Read image\n",
    "            image = io.imread(image_path)\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "def average_binary_images(image_list):\n",
    "    # Convert the list of images into numpy array\n",
    "    images_array = np.array(image_list)\n",
    "    # Sum the array along the first axis (image index)\n",
    "    summed_array = np.sum(images_array, axis=0)\n",
    "    # Divide by the number of images to get the average\n",
    "    average_array = summed_array / len(image_list)\n",
    "    return average_array\n",
    "\n",
    "folder_path = r'/path/to/dataset/predictions_needs_averaging'\n",
    "binary_images = read_binary_images(folder_path)\n",
    "average_image = average_binary_images(binary_images)\n",
    "\n",
    "# Save the average image\n",
    "output_path =os.path.join(folder_path, \"average_image.bmp\")\n",
    "io.imsave(output_path, average_image.astype(np.uint8))  # Ensure the data type is uint8 for binary image\n",
    "\n",
    "print(\"Average image saved to:\", output_path)\n",
    "\n",
    "# save the result of average image into path and convert to binary\n",
    "\n",
    "# Assuming your uint8 array is stored in a variable named 'uint8_array'\n",
    "image = cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)  \n",
    "\n",
    "# Convert the image to a uint8 array\n",
    "uint8_array = image.astype(np.uint8)\n",
    "\n",
    "# Reshape the uint8 array into an image shape (height, width)\n",
    "image_shape = (256, 256)  # specify the height and width of your image\n",
    "binary_image = uint8_array.reshape(image_shape)\n",
    "\n",
    "# Threshold the image to create a binary image\n",
    "threshold_value = 127  # You can adjust this threshold value as per your requirement\n",
    "_, binary_image = cv2.threshold(binary_image, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Show the binary image\n",
    "output_path =os.path.join(folder_path, \"average_image_b.bmp\")\n",
    "cv2.imwrite(output_path, binary_image)\n",
    "\n",
    "print(\"Image saved successfully at:\", output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show overlay of images, masks and predictions\n",
    "#import cv2\n",
    "#import numpy as np\n",
    "#import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_image_with_contours(image, mask, prediction):\n",
    "    \"\"\"\n",
    "    Plots an image with contours of the mask and prediction.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Original image (H x W x C).\n",
    "        mask (numpy.ndarray): Ground-truth mask (H x W).\n",
    "        prediction (numpy.ndarray): Predicted mask (H x W).\n",
    "    \"\"\"\n",
    "    # Convert image to RGB if it is grayscale\n",
    "    if len(image.shape) == 2:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    else:\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Resize mask and prediction to match the image size\n",
    "    mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "    prediction_resized = cv2.resize(prediction, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    # Find contours for the resized mask and prediction\n",
    "    mask_contours, _ = cv2.findContours(mask_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    prediction_contours, _ = cv2.findContours(prediction_resized, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw contours on a copy of the original image\n",
    "    image_with_contours = image_rgb.copy()\n",
    "    cv2.drawContours(image_with_contours, mask_contours, -1, (0, 0, 255), 2)        # Blue for mask\n",
    "    cv2.drawContours(image_with_contours, prediction_contours, -1, (255, 0, 0), 2)  # Red for prediction\n",
    "\n",
    "    # Plot the image\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    plt.imshow(image_with_contours)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"{base_name}: Mask (Blue) and Prediction (Red)\")\n",
    "\n",
    "    # Save each figure with an incrementing filename\n",
    "    filename = os.path.join(output_dir, f\"{base_name}.png\")\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Process folder of images\n",
    "if __name__ == \"__main__\":\n",
    "      \n",
    "    main_path='/path/to/dataset/Fold1'\n",
    "    image_folder = main_path+r'\\Test\\Images'\n",
    "    mask_folder = main_path+r'\\Test\\Masks'\n",
    "    prediction_folder = main_path+r'\\Result_att\\Predictions_PostPro'\n",
    "    output_dir= main_path+r'\\Result_att\\Results-overlay'\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Ensure folders exist\n",
    "    if not os.path.exists(image_folder) or not os.path.exists(mask_folder) or not os.path.exists(prediction_folder):\n",
    "        print(\"Error: One or more folders do not exist.\")\n",
    "        exit()\n",
    "\n",
    "    # List all files in the folders\n",
    "    image_files = sorted(os.listdir(image_folder))\n",
    "    mask_files = sorted(os.listdir(mask_folder))\n",
    "    prediction_files = sorted(os.listdir(prediction_folder))\n",
    "\n",
    "    # Process files that match by the first 11 characters to ensure working on the slices of the same patient\n",
    "    for image_file in image_files:\n",
    "        base_name = image_file[:11]  # Match based on first 11 characters\n",
    "        matching_mask = next((f for f in mask_files if f.startswith(base_name)), None)\n",
    "        matching_prediction = next((f for f in prediction_files if f.startswith(base_name)), None)\n",
    "\n",
    "        if matching_mask and matching_prediction:\n",
    "            # Load the files\n",
    "            image_path = os.path.join(image_folder, image_file)\n",
    "            mask_path = os.path.join(mask_folder, matching_mask)\n",
    "            prediction_path = os.path.join(prediction_folder, matching_prediction)\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            prediction = cv2.imread(prediction_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Check if files are loaded correctly\n",
    "            if image is None:\n",
    "                print(f\"Error: Unable to load image from '{image_path}'\")\n",
    "                continue\n",
    "            if mask is None:\n",
    "                print(f\"Error: Unable to load mask from '{mask_path}'\")\n",
    "                continue\n",
    "            if prediction is None:\n",
    "                print(f\"Error: Unable to load prediction from '{prediction_path}'\")\n",
    "                continue\n",
    "\n",
    "            # Ensure masks are binary (0 or 255)\n",
    "            _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "            _, prediction = cv2.threshold(prediction, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "            # Plot the image with contours\n",
    "            plot_image_with_contours(image, mask, prediction)\n",
    "        else:\n",
    "            print(f\"No matching mask or prediction for image '{image_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
